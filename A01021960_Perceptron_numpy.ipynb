{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A01021960_Perceptron_numpy.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UmzxNhOa8GF6"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielroa98/Redes-Neuronales/blob/main/A01021960_Perceptron_numpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmzxNhOa8GF6"
      },
      "source": [
        "# The Perceptron Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7XEefN-8GF9"
      },
      "source": [
        "A Perceptron is a system that learns using labeled examples of feature vectors, mapping these inputs to their corresponding output class labels. In its simplest form, a Perceptron contains N input nodes, one for each entry in the input row, followed by only one layer in the network with just a single node in that layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_HrrPXf8GF-"
      },
      "source": [
        "Training a Perceptron is a fairly straightforward operation. Our goal is to obtain a set of weights *w* that accurately classifies each instance in our training set. In order to train our Perceptron, we iteratively feed the network our training data multiple times. Each time the network has seen the full set of training data, we say an epoch has passed. It normally takes many epochs until a weight vector _w_ can be learned to linearly separate our two classes of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYVOOpEfFxR4"
      },
      "source": [
        "![Perceptron](https://drive.google.com/uc?id=1K7olbB11mSfAwPmB8BeeRNe6XbuGSK4D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmywjsFM8GF-"
      },
      "source": [
        "The pseudocode is the following:\n",
        "1. Initialize our weight vector w with small random values\n",
        "2. Until Perceptron converges\n",
        "    1. Loop over each input and class label\n",
        "    2. Take $x$ and pass it through the network, calculating the output value: $y = (w · x)$\n",
        "    3. Update the weights: if ŷ = 0 --> $w_i = w_i + \\alpha x_i$, if ŷ = 1 --> $w_i = w_i - \\alpha x_i$\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_s6txe2jYz-"
      },
      "source": [
        "# Script using Numpy\n",
        "## Daniel Roa - A01021960\n",
        "## Delivery date: 12/07/2021"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSYcra3n8iUG"
      },
      "source": [
        "import random, math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYXUulX-8GGA"
      },
      "source": [
        "class Perceptron:        \n",
        "    \"\"\"Perceptron class\n",
        "\n",
        "        Args:\n",
        "            M: Number of inputs\n",
        "            alpha: Learning rate\n",
        "        \n",
        "        Attributes:\n",
        "            W: The weights for the perceptron\n",
        "            b: bias\n",
        "            alpha: The learning rate\n",
        "    \"\"\"\n",
        "    def __init__(self, N, M, alpha=0.5):        \n",
        "        # Creates an array of N weights and initializes with random values\n",
        "        # define inputs\n",
        "        self.alpha = alpha\n",
        "        self.b = np.random.rand(1, 1)\n",
        "        self.error = []\n",
        "        self.M = M\n",
        "        self.posX = []\n",
        "        self.W = np.random.uniform(0, 1, size=N)\n",
        "            \n",
        "    def sigmoid(self, x):\n",
        "        return (1/(1 + math.e**(-x)))\n",
        "\n",
        "    def loss(self, yHat, y):\n",
        "      '''\n",
        "        Function in charge of calculating the Loss function (L).\n",
        "\n",
        "        Args:\n",
        "          yHat: equals to y with a hat on a regular equation, it's the predictions' values.\n",
        "          y: \n",
        "      '''\n",
        "      return (-(y * np.log(yHat) + (1 - y) * np.log(1 - yHat)))\n",
        "\n",
        "    \n",
        "    def predict(self, x):\n",
        "        \"\"\"\n",
        "            Makes a prediction for the specified input\n",
        "            \n",
        "            Args:\n",
        "                x: Input to make a prediction on.\n",
        "        \"\"\"\n",
        "        return self.sigmoid(np.dot(x, self.W)+ self.b)\n",
        "    \n",
        "    def perceptronStep(self, X, y):\n",
        "        \"\"\"\n",
        "            The perceptron basic step. It updates the weights based on the input data.\n",
        "            \n",
        "            Args:\n",
        "                X: Array with the input data\n",
        "                y: Data labels\n",
        "        \"\"\"\n",
        "        # Variables that will hold different information\n",
        "        J = 0\n",
        "        L = 0\n",
        "        db = 0\n",
        "        dw = 0\n",
        "        dw1 = 0\n",
        "        dw2 = 0\n",
        "        \n",
        "        # yHat = self.sigmoid(np.dot(X, self.W) + self.b)\n",
        "        yHat = self.predict(X)\n",
        "        J += self.loss(yHat, y)\n",
        "\n",
        "        dy = yHat - y\n",
        "        dw += np.dot(X.T, dy) / self.M\n",
        "        db += dy / self.M\n",
        "\n",
        "        # IMPORTANT\n",
        "        # Couldn't fix the self.b -= (db * self.alpha) issue\n",
        "        # Couldn't fix the self.W -= (dw * self.alpha) issue\n",
        "        self.W = (dw * self.alpha)\n",
        "        self.b = (db * self.alpha)\n",
        "\n",
        "        return\n",
        "    \n",
        "    def train(self, X, y, epochs = 10):\n",
        "        \"\"\"\n",
        "            Runs the perceptron step a specified number of epochs\n",
        "            \n",
        "            Args:\n",
        "                X: input data\n",
        "                y: labels\n",
        "                epochs: The number of times the step is executed\n",
        "        \"\"\"\n",
        "        # loop over the desired epochs\n",
        "        for epoch in range(epochs):\n",
        "            self.perceptronStep(X, y)\n",
        "        return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmsoic3Bi2vG"
      },
      "source": [
        "## Execution of the AND data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZfEuLw48GGB",
        "outputId": "ed2a3574-0bbb-4b97-b856-3cebc0c0bfe9"
      },
      "source": [
        "# change the seed to see different solutions\n",
        "random.seed(42)\n",
        "\n",
        "# The following data is used to train the perceptron for the AND operation\n",
        "# Test your code with the OR operation\n",
        "X = np.array([[0,0],[0,1], [1,0], [1,1]])\n",
        "y = np.array([[0],[0], [0], [1]])\n",
        "\n",
        "m = len(y)\n",
        "\n",
        "p = Perceptron(2, m)\n",
        "print(f\"Initial weights {p.W}\")\n",
        "# print(f'Shapes\\nInput X {X.shape}\\nInput y {y.shape}\\nWeights {p.W.shape}')\n",
        "\n",
        "# Test training with different epochs\n",
        "p.train(X, y, 25)\n",
        "print(f\"Weights after training {p.W}\")\n",
        "\n",
        "# Test your model with a prediction\n",
        "prediction = p.predict(np.array([0,1]))\n",
        "print(f'Prediction for {[0, 1]} is {p.predict(np.array([0,1]))}')\n",
        "# print(f'Prediction for {X[1]} is {p.predict(X[1])}')\n",
        "# print(f'Prediction for {X[2]} is {p.predict(X[2])}')\n",
        "# print(f'Prediction for {X[3]} is {p.predict(X[3])}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial weights [0.3944054  0.99227021]\n",
            "Weights after training [[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n",
            "Prediction for [0, 1] is [[0.51612326 0.51612326 0.51612326 0.51612326]\n",
            " [0.51612326 0.51612326 0.51612326 0.51612326]\n",
            " [0.51612326 0.51612326 0.51612326 0.51612326]\n",
            " [0.48387674 0.48387674 0.48387674 0.48387674]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJhxq6zUjUXX"
      },
      "source": [
        "## Execution of the OR data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgT_DLl1idep",
        "outputId": "9d64184b-7564-4693-ace2-c52e60eaeaef"
      },
      "source": [
        "# change the seed to see different solutions\n",
        "random.seed(42)\n",
        "\n",
        "# The following data is used to train the perceptron for the AND operation\n",
        "# Test your code with the OR operation\n",
        "X = np.array([[0,0],[0,1], [1,0], [1,1]])\n",
        "# OR data\n",
        "y = np.array([[0],[1], [1], [1]])\n",
        "\n",
        "m = len(y)\n",
        "\n",
        "p = Perceptron(2, m)\n",
        "print(f\"Initial weights {p.W}\")\n",
        "# print(f'Shapes\\nInput X {X.shape}\\nInput y {y.shape}\\nWeights {p.W.shape}')\n",
        "\n",
        "# Test training with different epochs\n",
        "p.train(X, y, 25)\n",
        "print(f\"Weights after training {p.W}\")\n",
        "\n",
        "# Test your model with a prediction\n",
        "prediction = p.predict(np.array([0,1]))\n",
        "print(f'Prediction for {[0, 1]} is {p.predict(np.array([0,1]))}')\n",
        "\n",
        "#print(f'Prediction for {X[1]} is {p.predict(X[1])}')\n",
        "#print(f'Prediction for {X[2]} is {p.predict(X[2])}')\n",
        "#print(f'Prediction for {X[3]} is {p.predict(X[3])}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial weights [0.54670772 0.51992338]\n",
            "Weights after training [[-0.14269306 -0.14269306 -0.14269306 -0.14269306]\n",
            " [-0.14269306 -0.14269306 -0.14269306 -0.14269306]]\n",
            "Prediction for [0, 1] is [[0.48046553 0.48046553 0.48046553 0.48046553]\n",
            " [0.44725033 0.44725033 0.44725033 0.44725033]\n",
            " [0.44725033 0.44725033 0.44725033 0.44725033]\n",
            " [0.44613672 0.44613672 0.44613672 0.44613672]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPLr3yy0vHQ2"
      },
      "source": [
        "# Fixes seen in class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RaCVPUsv4qh"
      },
      "source": [
        "import random, math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrzG6GrzvNQ9"
      },
      "source": [
        "class Perceptron:        \n",
        "    \"\"\"Perceptron class\n",
        "\n",
        "        Args:\n",
        "            M: Number of inputs\n",
        "            alpha: Learning rate\n",
        "        \n",
        "        Attributes:\n",
        "            W: The weights for the perceptron\n",
        "            b: bias\n",
        "            alpha: The learning rate\n",
        "    \"\"\"\n",
        "    def __init__(self, N, M, alpha=0.5):        \n",
        "        # Creates an array of N weights and initializes with random values\n",
        "        # define inputs\n",
        "        self.alpha = alpha\n",
        "        # self.b = np.random.rand(1, 1)\n",
        "        self.b = random.uniform(0, 1) # Corrected version\n",
        "        self.error = []\n",
        "        self.M = M\n",
        "        self.posX = []\n",
        "        # self.W = np.random.uniform(0, 1, size=N)\n",
        "        self.W = np.random.rand(2, 1) # Corrected version 2 <- representa los inputs 1 <- representa los # de conexiones de la siguiente capa \n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / 1(np.exp(-x)) # <- esta preparado para recibir valores específicos de Numpy\n",
        "    \n",
        "    def sigmoid_der(x):\n",
        "      return (x)*(1-(x))\n",
        "\n",
        "    def loss(self, yHat, y):\n",
        "      '''\n",
        "        Function in charge of calculating the Loss function (L).\n",
        "\n",
        "        Args:\n",
        "          yHat: equals to y with a hat on a regular equation, it's the predictions' values.\n",
        "          y: \n",
        "      '''\n",
        "      return (-(y * np.log(yHat) + (1 - y) * np.log(1 - yHat)))\n",
        "\n",
        "    \n",
        "    def predict(self, x):\n",
        "        \"\"\"\n",
        "            Makes a prediction for the specified input\n",
        "            \n",
        "            Args:\n",
        "                x: Input to make a prediction on.\n",
        "        \"\"\"\n",
        "        return self.sigmoid(np.dot(x, self.W)+ self.b)\n",
        "    \n",
        "    def perceptronStep(self, X, y):\n",
        "        \"\"\"\n",
        "            The perceptron basic step. It updates the weights based on the input data.\n",
        "            \n",
        "            Args:\n",
        "                X: Array with the input data\n",
        "                y: Data labels\n",
        "        \"\"\"\n",
        "        # Variables that will hold different information\n",
        "        J = 0\n",
        "        L = 0\n",
        "        db = 0\n",
        "        dw = 0\n",
        "        dw1 = 0\n",
        "        dw2 = 0\n",
        "        \n",
        "        # yHat = self.sigmoid(np.dot(X, self.W) + self.b)\n",
        "        yHat = self.predict(X)\n",
        "        J += self.loss(yHat, y)\n",
        "\n",
        "        dy = yHat - y\n",
        "        dw += np.dot(X.T, dy) / self.M\n",
        "        db += dy / self.M\n",
        "\n",
        "        # IMPORTANT\n",
        "        # Couldn't fix the self.b -= (db * self.alpha) issue\n",
        "        # Couldn't fix the self.W -= (dw * self.alpha) issue\n",
        "        self.W = (dw * self.alpha)\n",
        "        self.b = (db * self.alpha)\n",
        "\n",
        "        return\n",
        "    \n",
        "    def train(self, X, y, epochs = 10):\n",
        "        \"\"\"\n",
        "            Runs the perceptron step a specified number of epochs\n",
        "            \n",
        "            Args:\n",
        "                X: input data\n",
        "                y: labels\n",
        "                epochs: The number of times the step is executed\n",
        "        \"\"\"\n",
        "        # loop over the desired epochs\n",
        "        for epoch in range(epochs):\n",
        "            self.perceptronStep(X, y)\n",
        "        return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tQN52XnvvPX"
      },
      "source": [
        "# change the seed to see different solutions\n",
        "random.seed(42)\n",
        "\n",
        "# The following data is used to train the perceptron for the AND operation\n",
        "# Test your code with the OR operation\n",
        "X = np.array([[0,0],[0,1], [1,0], [1,1]]).T\n",
        "y = np.array([[0],[0], [0], [1]])\n",
        "\n",
        "m = len(y)\n",
        "\n",
        "p = Perceptron(2, m)\n",
        "print(f\"Initial weights {p.W}\")\n",
        "# print(f'Shapes\\nInput X {X.shape}\\nInput y {y.shape}\\nWeights {p.W.shape}')\n",
        "\n",
        "# Test training with different epochs\n",
        "p.train(X, y, 25)\n",
        "print(f\"Weights after training {p.W}\")\n",
        "\n",
        "# Test your model with a prediction\n",
        "prediction = p.predict(np.array([0,1]))\n",
        "print(f'Prediction for {[0, 1]} is {p.predict(np.array([0,1]))}')\n",
        "# print(f'Prediction for {X[1]} is {p.predict(X[1])}')\n",
        "# print(f'Prediction for {X[2]} is {p.predict(X[2])}')\n",
        "# print(f'Prediction for {X[3]} is {p.predict(X[3])}')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}